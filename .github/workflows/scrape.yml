name: nightly-scrape

on:
  schedule:
    - cron: '0 5 * * *'         # daily at 05:00 UTC (midnight CT / 01:00 CDT)
  workflow_dispatch:           # allows manual runs
  push:
    paths:
      - 'scraper/**'           # rerun when scraper code changes

jobs:
  scrape:
    runs-on: ubuntu-latest
    environment: projecthelper  # picks up the secrets you set
    concurrency:
      group: scrape
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Run scraper
        run: python run_scraper.py
      - uses: actions/upload-artifact@v4
        with:
          name: listings-${{ github.run_id }}
          path: listings.csv
          retention-days: 14

