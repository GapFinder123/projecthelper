name: nightly-scrape

on:
  schedule:
    - cron: '0 5 * * *'       
  workflow_dispatch:           
  push:
    paths:
      - 'scraper/**'        

jobs:
  scrape:
    runs-on: ubuntu-latest
    environment: projecthelper
    env:
      SUPABASE_URL:  ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY:  ${{ secrets.SUPABASE_KEY }}
      RAPIDAPI_KEY:  ${{ secrets.RAPIDAPI_KEY }}
      RAPIDAPI_HOST: ${{ secrets.RAPIDAPI_HOST }}
    concurrency:
      group: scrape
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - run: pip install -r requirements.txt
      - name: Run scraper
        run: python ingest.py
      - uses: actions/upload-artifact@v4
        with:
          name: listings-${{ github.run_id }}
          path: listings.csv
          retention-days: 14

